{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f34d3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install flask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f0bc08",
   "metadata": {},
   "source": [
    "# IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73e4f8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import torch\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn, ssd300_vgg16\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.ssd import SSDClassificationHead\n",
    "import torchvision.ops as ops\n",
    "import json\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86281cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Flask app\n",
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "341165b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> cuda <--\n"
     ]
    }
   ],
   "source": [
    "# Load the models from specified paths\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'--> {device} <--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3932c0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the saved models\n",
    "SSD_path = r'C:\\Users\\krish\\Documents\\Summer\\Project\\model\\Sho.pth'\n",
    "FastRCNN_path = r'C:\\Users\\krish\\Documents\\Summer\\Project\\model\\Luna.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11d2f0e",
   "metadata": {},
   "source": [
    "# LABEL ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e226bd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load COCO categories for Fast R-CNN\n",
    "with open('coco/instances_train2017.json') as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "categories = coco_data['categories']\n",
    "original_ids = [category['id'] for category in categories]\n",
    "id_to_sequential_id = {original_id: idx for idx, original_id in enumerate(original_ids)}\n",
    "sequential_id_to_name = {idx: category['name'] for idx, category in enumerate(categories)}\n",
    "\n",
    "# Create a reverse mapping for Fast R-CNN\n",
    "sequential_id_to_original_id = {v: k for k, v in id_to_sequential_id.items()}\n",
    "\n",
    "# Load COCO categories for SSD\n",
    "category_id_to_name = {category['id']: category['name'] for category in categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eefbc727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bowl'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential_id_to_name[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1749e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8, 10: 9, 11: 10, 13: 11, 14: 12, 15: 13, 16: 14, 17: 15, 18: 16, 19: 17, 20: 18, 21: 19, 22: 20, 23: 21, 24: 22, 25: 23, 27: 24, 28: 25, 31: 26, 32: 27, 33: 28, 34: 29, 35: 30, 36: 31, 37: 32, 38: 33, 39: 34, 40: 35, 41: 36, 42: 37, 43: 38, 44: 39, 46: 40, 47: 41, 48: 42, 49: 43, 50: 44, 51: 45, 52: 46, 53: 47, 54: 48, 55: 49, 56: 50, 57: 51, 58: 52, 59: 53, 60: 54, 61: 55, 62: 56, 63: 57, 64: 58, 65: 59, 67: 60, 70: 61, 72: 62, 73: 63, 74: 64, 75: 65, 76: 66, 77: 67, 78: 68, 79: 69, 80: 70, 81: 71, 82: 72, 84: 73, 85: 74, 86: 75, 87: 76, 88: 77, 89: 78, 90: 79}\n"
     ]
    }
   ],
   "source": [
    "print(id_to_sequential_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "974de3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n"
     ]
    }
   ],
   "source": [
    "print(sequential_id_to_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98a1f423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'person', 2: 'bicycle', 3: 'car', 4: 'motorcycle', 5: 'airplane', 6: 'bus', 7: 'train', 8: 'truck', 9: 'boat', 10: 'traffic light', 11: 'fire hydrant', 13: 'stop sign', 14: 'parking meter', 15: 'bench', 16: 'bird', 17: 'cat', 18: 'dog', 19: 'horse', 20: 'sheep', 21: 'cow', 22: 'elephant', 23: 'bear', 24: 'zebra', 25: 'giraffe', 27: 'backpack', 28: 'umbrella', 31: 'handbag', 32: 'tie', 33: 'suitcase', 34: 'frisbee', 35: 'skis', 36: 'snowboard', 37: 'sports ball', 38: 'kite', 39: 'baseball bat', 40: 'baseball glove', 41: 'skateboard', 42: 'surfboard', 43: 'tennis racket', 44: 'bottle', 46: 'wine glass', 47: 'cup', 48: 'fork', 49: 'knife', 50: 'spoon', 51: 'bowl', 52: 'banana', 53: 'apple', 54: 'sandwich', 55: 'orange', 56: 'broccoli', 57: 'carrot', 58: 'hot dog', 59: 'pizza', 60: 'donut', 61: 'cake', 62: 'chair', 63: 'couch', 64: 'potted plant', 65: 'bed', 67: 'dining table', 70: 'toilet', 72: 'tv', 73: 'laptop', 74: 'mouse', 75: 'remote', 76: 'keyboard', 77: 'cell phone', 78: 'microwave', 79: 'oven', 80: 'toaster', 81: 'sink', 82: 'refrigerator', 84: 'book', 85: 'clock', 86: 'vase', 87: 'scissors', 88: 'teddy bear', 89: 'hair drier', 90: 'toothbrush'}\n"
     ]
    }
   ],
   "source": [
    "print(category_id_to_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f3e19a",
   "metadata": {},
   "source": [
    "# MODEL WEIGHT LOADING FROM \".PTH\" FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ce0d539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to load the Fast R-CNN model\n",
    "def load_fastrcnn_model(model_path, num_classes):\n",
    "    model = fasterrcnn_resnet50_fpn(pretrained=False)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93f2487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to load the SSD model\n",
    "def load_ssd_model(model_path, num_classes):\n",
    "    model = ssd300_vgg16(pretrained=False)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1f4a3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krish\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\krish\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load the models with classes\n",
    "FastRCNN = load_fastrcnn_model(FastRCNN_path, num_classes=81)\n",
    "SSD = load_ssd_model(SSD_path, num_classes=91)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96b2dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_image(image_bytes):\n",
    "    try:\n",
    "        image = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        return transform(image).unsqueeze(0), image\n",
    "    except UnidentifiedImageError:\n",
    "        raise ValueError(\"The uploaded file is not a valid image.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f16b39e",
   "metadata": {},
   "source": [
    "# NON-MAX SUPPRESSION AND IOU FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f967cae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to filter and apply non-max suppression\n",
    "def filter_and_nms(predictions, score_threshold=0.7, iou_threshold=0.7):\n",
    "    filtered_predictions = []\n",
    "    for prediction in predictions:\n",
    "        boxes = prediction['boxes']\n",
    "        scores = prediction['scores']\n",
    "        labels = prediction['labels']\n",
    "\n",
    "        # Filter by score\n",
    "        keep = scores >= score_threshold\n",
    "        boxes = boxes[keep]\n",
    "        scores = scores[keep]\n",
    "        labels = labels[keep]\n",
    "\n",
    "        # Apply non-max suppression\n",
    "        keep = ops.nms(boxes, scores, iou_threshold)\n",
    "        filtered_predictions.append({\n",
    "            'boxes': boxes[keep],\n",
    "            'scores': scores[keep],\n",
    "            'labels': labels[keep]\n",
    "        })\n",
    "\n",
    "    return filtered_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "150e4fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to draw bounding boxes on the image\n",
    "def draw_boxes(image, predictions, label_map):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    font = ImageFont.load_default()\n",
    "    for prediction in predictions:\n",
    "        for i in range(len(prediction[\"boxes\"])):\n",
    "            box = prediction[\"boxes\"][i].cpu().numpy().tolist()\n",
    "            score = prediction[\"scores\"][i].cpu().numpy().tolist()\n",
    "            label = prediction[\"labels\"][i].cpu().numpy().tolist()\n",
    "            x0, y0, x1, y1 = box\n",
    "            draw.rectangle([x0, y0, x1, y1], outline=\"red\", width=2)\n",
    "            text = f\"{label_map.get(label, 'Unknown')}: {score:.2f}\"\n",
    "            text_bbox = draw.textbbox((x0, y0), text, font=font)\n",
    "            text_background = [x0, y0 - (text_bbox[3] - text_bbox[1]), x0 + (text_bbox[2] - text_bbox[0]), y0]\n",
    "            draw.rectangle(text_background, fill=\"red\")\n",
    "            draw.text((x0, y0 - (text_bbox[3] - text_bbox[1])), text, fill=\"white\", font=font)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa30f7bb",
   "metadata": {},
   "source": [
    "# MODEL PROCESSING AND DETECTION!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "197dff90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the route to render the HTML form\n",
    "@app.route(\"/\", methods=[\"GET\"])\n",
    "def index():\n",
    "    return render_template(\"index.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a78d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/predict/fastrcnn\", methods=[\"POST\"])\n",
    "def predict_fastrcnn():\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({\"error\": \"No file provided\"}), 400\n",
    "    file = request.files['file']\n",
    "    image_bytes = file.read()\n",
    "    image_tensor, image = transform_image(image_bytes)\n",
    "    image_tensor = image_tensor.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = FastRCNN(image_tensor)\n",
    "\n",
    "    # Filter and apply non-max suppression\n",
    "    nms_prediction = filter_and_nms(prediction, score_threshold=0.7, iou_threshold=0.7)\n",
    "\n",
    "    # Check if there are any predictions\n",
    "    if nms_prediction and any(len(pred['boxes']) > 0 for pred in nms_prediction):\n",
    "        # Draw bounding boxes on the image\n",
    "        image_with_boxes = draw_boxes(image, nms_prediction, sequential_id_to_name)\n",
    "\n",
    "        # Convert image to base64\n",
    "        buffered = io.BytesIO()\n",
    "        image_with_boxes.save(buffered, format=\"JPEG\")\n",
    "        img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "        results = []\n",
    "        for element in nms_prediction:\n",
    "            for i in range(len(element[\"boxes\"])):\n",
    "                score = element[\"scores\"][i].cpu().numpy().tolist() * 100\n",
    "                label = element[\"labels\"][i].cpu().numpy().tolist()\n",
    "                original_id = sequential_id_to_original_id.get(label, 'Unknown')\n",
    "                results.append({\n",
    "                    \"score\": f\"{score:.2f}%\",\n",
    "                    \"label\": category_id_to_name[original_id]\n",
    "                })\n",
    "                    \n",
    "        return jsonify({\"prediction\": results, \"image\": img_str})\n",
    "    else:\n",
    "        return jsonify({\"prediction\": \"No objects detected\", \"image\": None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d74c2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/predict/ssd300\", methods=[\"POST\"])\n",
    "def predict_ssd300():\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({\"error\": \"No file provided\"}), 400\n",
    "    file = request.files['file']\n",
    "    image_bytes = file.read()\n",
    "    image_tensor, image = transform_image(image_bytes)\n",
    "    image_tensor = image_tensor.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = SSD(image_tensor)\n",
    "\n",
    "    # Filter and apply non-max suppression\n",
    "    nms_prediction = filter_and_nms(prediction, score_threshold=0.7, iou_threshold=0.7)\n",
    "\n",
    "    # Check if there are any predictions\n",
    "    if nms_prediction and any(len(pred['boxes']) > 0 for pred in nms_prediction):\n",
    "        # Draw bounding boxes on the image\n",
    "        image_with_boxes = draw_boxes(image, nms_prediction, category_id_to_name)\n",
    "\n",
    "        # Convert image to base64\n",
    "        buffered = io.BytesIO()\n",
    "        image_with_boxes.save(buffered, format=\"JPEG\")\n",
    "        img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "        results = []\n",
    "        for element in nms_prediction:\n",
    "            for i in range(len(element[\"boxes\"])):\n",
    "                score = element[\"scores\"][i].cpu().numpy().tolist() * 100\n",
    "                label = element[\"labels\"][i].cpu().numpy().tolist()\n",
    "                results.append({\n",
    "                    \"score\": f\"{score:.2f}%\",\n",
    "                    \"label\": category_id_to_name[label]\n",
    "                })\n",
    "\n",
    "        return jsonify({\"prediction\": results, \"image\": img_str})\n",
    "    else:\n",
    "        return jsonify({\"prediction\": \"No objects detected\", \"image\": None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9be821c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8000\n",
      " * Running on http://192.168.1.63:8000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [05/Jul/2024 15:51:13] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Run the app\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"0.0.0.0\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329fdbbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
